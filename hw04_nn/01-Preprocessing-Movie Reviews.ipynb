{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from K_nearest import K_nearest\n",
    "\n",
    "with open(\"reviewstrain.txt\", \"r\") as file:\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for line in file:\n",
    "        # exclude the label\n",
    "        X_train.append(line[1:].strip())\n",
    "        y_train.append(int(line[0]))\n",
    "\n",
    "with open(\"reviewstest.txt\", \"r\") as file:\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for line in file:\n",
    "        X_test.append(line[1:].strip())\n",
    "        y_test.append(int(line[0]))\n",
    "\n",
    "corpus = X_train + X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "d_t_matrix= vectorizer.fit_transform(X_train)\n",
    "voc_idx = d_t_matrix.sum(axis=0)\n",
    "vocabulary = np.asarray(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experienment and Check the first sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['films', 'horror', '1930s', 'beast', 'the', 'beauty', 'of',\n",
       "       'imagining', 're', 'transporting', 'finally', 'and', 'funny',\n",
       "       'stirring'], dtype='<U17')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[d_t_matrix[0].nonzero()[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  term  freq\n",
       "0   10     5\n",
       "1  100     1\n",
       "2  105     1\n",
       "3   11     2\n",
       "4   12     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = {'term': vectorizer.get_feature_names(), 'freq':np.asarray(voc_idx).squeeze()}\n",
    "voc_df = pd.DataFrame(temp)\n",
    "voc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 5 most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>the</td>\n",
       "      <td>1262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>and</td>\n",
       "      <td>923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3382</th>\n",
       "      <td>of</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5082</th>\n",
       "      <td>to</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>is</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     term  freq\n",
       "5004  the  1262\n",
       "225   and   923\n",
       "3382   of   826\n",
       "5082   to   529\n",
       "2643   is   466"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_df.nlargest(5, 'freq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The entropy of the whole sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9952229310409332\n"
     ]
    }
   ],
   "source": [
    "n_1 = y_train.sum()\n",
    "n_t = y_train.shape[0]\n",
    "n_0 = n_t -n_1\n",
    "total_entropy = -((n_1/n_t)*np.log2(n_1/n_t) + (n_0/n_t)*np.log2(n_0/n_t))\n",
    "print(total_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " array([1872, 2379,   11,  443, 5004,  448, 3382, 2453, 3935, 5143, 1875,\n",
       "         225, 2031, 4747], dtype=int32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_t_matrix[0].nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_t_ndarr = d_t_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('store/',d_t_ndarr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the infomation gain of every attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# When the token is equal to 1\n",
    "num_total_dic = defaultdict(lambda:0)\n",
    "num_1_dic = defaultdict(lambda:0)\n",
    "num_0_dic = defaultdict(lambda:0)\n",
    "\n",
    "for i, s in enumerate(d_t_ndarr):\n",
    "    for idx in s.nonzero()[0]:\n",
    "        num_total_dic[idx] += 1\n",
    "        if y_train[i] == 1:\n",
    "            num_1_dic[idx] += 1\n",
    "        else:\n",
    "            num_0_dic[idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When the token is equal to 0\n",
    "_num_total_dic = defaultdict(lambda:0)\n",
    "_num_1_dic = defaultdict(lambda:0)\n",
    "_num_0_dic = defaultdict(lambda:0)\n",
    "for i, s in enumerate(d_t_ndarr):\n",
    "    for idx in np.where(s==0)[0]:\n",
    "        _num_total_dic[idx] += 1\n",
    "        if y_train[i] == 1:\n",
    "            _num_1_dic[idx] += 1\n",
    "        else:\n",
    "            _num_0_dic[idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>freq</th>\n",
       "      <th>num_total</th>\n",
       "      <th>num_1</th>\n",
       "      <th>num_0</th>\n",
       "      <th>_num_total</th>\n",
       "      <th>_num_1</th>\n",
       "      <th>_num_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1495</td>\n",
       "      <td>809</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1499</td>\n",
       "      <td>811</td>\n",
       "      <td>688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1499</td>\n",
       "      <td>811</td>\n",
       "      <td>688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1498</td>\n",
       "      <td>810</td>\n",
       "      <td>688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1499</td>\n",
       "      <td>810</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  term  freq  num_total  num_1  num_0  _num_total  _num_1  _num_0\n",
       "0   10     5          5    2.0    3.0        1495     809     686\n",
       "1  100     1          1    0.0    1.0        1499     811     688\n",
       "2  105     1          1    0.0    1.0        1499     811     688\n",
       "3   11     2          2    1.0    1.0        1498     810     688\n",
       "4   12     1          1    1.0    0.0        1499     810     689"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add new columns\n",
    "df1 = pd.DataFrame.from_dict(data= num_total_dic, orient='index', columns=['num_total'])\n",
    "df2 = pd.DataFrame.from_dict(data= num_1_dic, orient='index', columns=['num_1'])\n",
    "df3 = pd.DataFrame.from_dict(data= num_0_dic, orient='index', columns=['num_0'])\n",
    "df4 = pd.DataFrame.from_dict(data= _num_total_dic, orient='index', columns=['_num_total'])\n",
    "df5 = pd.DataFrame.from_dict(data= _num_1_dic, orient='index', columns=['_num_1'])\n",
    "df6 = pd.DataFrame.from_dict(data= _num_0_dic, orient='index', columns=['_num_0'])\n",
    "new_voc_df = voc_df.join(df1)\n",
    "new_voc_df = new_voc_df.join(df2)\n",
    "new_voc_df = new_voc_df.join(df3)\n",
    "new_voc_df = new_voc_df.join(df4)\n",
    "new_voc_df = new_voc_df.join(df5)\n",
    "new_voc_df = new_voc_df.join(df6)\n",
    "# Fill NaN with 0\n",
    "new_voc_df = new_voc_df.fillna(0)\n",
    "new_voc_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zl2501/.conda/envs/fastai/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log2\n",
      "  \n",
      "/home/zl2501/.conda/envs/fastai/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log2\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "def get_information_gain(x):\n",
    "    e1 = -(x.num_0/x.num_total*np.log2(x.num_0/x.num_total) \n",
    "             + x.num_1/x.num_total*np.log2(x.num_1/x.num_total))\n",
    "    e2 = -(x._num_0/x._num_total*np.log2(x._num_0/x._num_total) \n",
    "             + x._num_1/x._num_total*np.log2(x._num_1/x._num_total))\n",
    "    after = x.num_total/d_t_ndarr.shape[0] * e1+ x._num_total/d_t_ndarr.shape[0] * e2\n",
    "    return total_entropy-after\n",
    "\n",
    "new_voc_df=new_voc_df.assign(information_gain= lambda x: get_information_gain(x))\n",
    "new_voc_df = new_voc_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>freq</th>\n",
       "      <th>num_total</th>\n",
       "      <th>num_1</th>\n",
       "      <th>num_0</th>\n",
       "      <th>_num_total</th>\n",
       "      <th>_num_1</th>\n",
       "      <th>_num_0</th>\n",
       "      <th>information_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>bad</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1452</td>\n",
       "      <td>808</td>\n",
       "      <td>644</td>\n",
       "      <td>0.025357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>best</td>\n",
       "      <td>49</td>\n",
       "      <td>47</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1453</td>\n",
       "      <td>766</td>\n",
       "      <td>687</td>\n",
       "      <td>0.020668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>too</td>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1465</td>\n",
       "      <td>806</td>\n",
       "      <td>659</td>\n",
       "      <td>0.011856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>moving</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1474</td>\n",
       "      <td>786</td>\n",
       "      <td>688</td>\n",
       "      <td>0.011615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>and</td>\n",
       "      <td>923</td>\n",
       "      <td>739</td>\n",
       "      <td>444.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>761</td>\n",
       "      <td>367</td>\n",
       "      <td>394</td>\n",
       "      <td>0.010230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>entertaining</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1477</td>\n",
       "      <td>789</td>\n",
       "      <td>688</td>\n",
       "      <td>0.009924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>minutes</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1478</td>\n",
       "      <td>809</td>\n",
       "      <td>669</td>\n",
       "      <td>0.009830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5036</th>\n",
       "      <td>this</td>\n",
       "      <td>206</td>\n",
       "      <td>201</td>\n",
       "      <td>80.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1299</td>\n",
       "      <td>731</td>\n",
       "      <td>568</td>\n",
       "      <td>0.009135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5577</th>\n",
       "      <td>with</td>\n",
       "      <td>198</td>\n",
       "      <td>183</td>\n",
       "      <td>126.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1317</td>\n",
       "      <td>685</td>\n",
       "      <td>632</td>\n",
       "      <td>0.009075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>dull</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1480</td>\n",
       "      <td>809</td>\n",
       "      <td>671</td>\n",
       "      <td>0.008500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5614</th>\n",
       "      <td>worst</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1484</td>\n",
       "      <td>810</td>\n",
       "      <td>674</td>\n",
       "      <td>0.008294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3425</th>\n",
       "      <td>or</td>\n",
       "      <td>65</td>\n",
       "      <td>59</td>\n",
       "      <td>17.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1441</td>\n",
       "      <td>794</td>\n",
       "      <td>647</td>\n",
       "      <td>0.007706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>no</td>\n",
       "      <td>47</td>\n",
       "      <td>44</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1456</td>\n",
       "      <td>800</td>\n",
       "      <td>656</td>\n",
       "      <td>0.007619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>why</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1485</td>\n",
       "      <td>810</td>\n",
       "      <td>675</td>\n",
       "      <td>0.007599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3579</th>\n",
       "      <td>performance</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1477</td>\n",
       "      <td>790</td>\n",
       "      <td>687</td>\n",
       "      <td>0.007478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>movie</td>\n",
       "      <td>223</td>\n",
       "      <td>220</td>\n",
       "      <td>92.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1280</td>\n",
       "      <td>719</td>\n",
       "      <td>561</td>\n",
       "      <td>0.007472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3672</th>\n",
       "      <td>plot</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1476</td>\n",
       "      <td>807</td>\n",
       "      <td>669</td>\n",
       "      <td>0.007036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>love</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1467</td>\n",
       "      <td>783</td>\n",
       "      <td>684</td>\n",
       "      <td>0.006939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3108</th>\n",
       "      <td>mess</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1486</td>\n",
       "      <td>810</td>\n",
       "      <td>676</td>\n",
       "      <td>0.006910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4567</th>\n",
       "      <td>so</td>\n",
       "      <td>77</td>\n",
       "      <td>73</td>\n",
       "      <td>24.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1427</td>\n",
       "      <td>787</td>\n",
       "      <td>640</td>\n",
       "      <td>0.006720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>script</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1475</td>\n",
       "      <td>806</td>\n",
       "      <td>669</td>\n",
       "      <td>0.005986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>get</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1481</td>\n",
       "      <td>808</td>\n",
       "      <td>673</td>\n",
       "      <td>0.005845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3580</th>\n",
       "      <td>performances</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1460</td>\n",
       "      <td>779</td>\n",
       "      <td>681</td>\n",
       "      <td>0.005804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5619</th>\n",
       "      <td>would</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1473</td>\n",
       "      <td>805</td>\n",
       "      <td>668</td>\n",
       "      <td>0.005604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>documentary</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1477</td>\n",
       "      <td>791</td>\n",
       "      <td>686</td>\n",
       "      <td>0.005583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>any</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1458</td>\n",
       "      <td>799</td>\n",
       "      <td>659</td>\n",
       "      <td>0.005530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5508</th>\n",
       "      <td>well</td>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1455</td>\n",
       "      <td>776</td>\n",
       "      <td>679</td>\n",
       "      <td>0.005409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>it</td>\n",
       "      <td>364</td>\n",
       "      <td>320</td>\n",
       "      <td>147.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1180</td>\n",
       "      <td>664</td>\n",
       "      <td>516</td>\n",
       "      <td>0.005190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>fascinating</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1486</td>\n",
       "      <td>798</td>\n",
       "      <td>688</td>\n",
       "      <td>0.005011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>predictable</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1489</td>\n",
       "      <td>810</td>\n",
       "      <td>679</td>\n",
       "      <td>0.004883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>if</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>20.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1441</td>\n",
       "      <td>791</td>\n",
       "      <td>650</td>\n",
       "      <td>0.004864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>feels</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1483</td>\n",
       "      <td>808</td>\n",
       "      <td>675</td>\n",
       "      <td>0.004681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>first</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1473</td>\n",
       "      <td>789</td>\n",
       "      <td>684</td>\n",
       "      <td>0.004382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>long</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1481</td>\n",
       "      <td>807</td>\n",
       "      <td>674</td>\n",
       "      <td>0.004236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5513</th>\n",
       "      <td>were</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1481</td>\n",
       "      <td>807</td>\n",
       "      <td>674</td>\n",
       "      <td>0.004236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>hour</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1490</td>\n",
       "      <td>810</td>\n",
       "      <td>680</td>\n",
       "      <td>0.004224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>less</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1490</td>\n",
       "      <td>810</td>\n",
       "      <td>680</td>\n",
       "      <td>0.004224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5229</th>\n",
       "      <td>ugly</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1490</td>\n",
       "      <td>810</td>\n",
       "      <td>680</td>\n",
       "      <td>0.004224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5400</th>\n",
       "      <td>video</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1490</td>\n",
       "      <td>810</td>\n",
       "      <td>680</td>\n",
       "      <td>0.004224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>may</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1480</td>\n",
       "      <td>794</td>\n",
       "      <td>686</td>\n",
       "      <td>0.004218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3447</th>\n",
       "      <td>out</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>24.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1434</td>\n",
       "      <td>787</td>\n",
       "      <td>647</td>\n",
       "      <td>0.004197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>half</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1484</td>\n",
       "      <td>808</td>\n",
       "      <td>676</td>\n",
       "      <td>0.004117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>fun</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1477</td>\n",
       "      <td>792</td>\n",
       "      <td>685</td>\n",
       "      <td>0.004066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>romantic</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1484</td>\n",
       "      <td>797</td>\n",
       "      <td>687</td>\n",
       "      <td>0.004016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>brilliant</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1488</td>\n",
       "      <td>800</td>\n",
       "      <td>688</td>\n",
       "      <td>0.003970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066</th>\n",
       "      <td>me</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1482</td>\n",
       "      <td>807</td>\n",
       "      <td>675</td>\n",
       "      <td>0.003714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5082</th>\n",
       "      <td>to</td>\n",
       "      <td>529</td>\n",
       "      <td>435</td>\n",
       "      <td>211.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>1065</td>\n",
       "      <td>600</td>\n",
       "      <td>465</td>\n",
       "      <td>0.003661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>great</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1478</td>\n",
       "      <td>793</td>\n",
       "      <td>685</td>\n",
       "      <td>0.003656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>fails</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1491</td>\n",
       "      <td>810</td>\n",
       "      <td>681</td>\n",
       "      <td>0.003577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>goes</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1491</td>\n",
       "      <td>810</td>\n",
       "      <td>681</td>\n",
       "      <td>0.003577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              term  freq  num_total  num_1  num_0  _num_total  _num_1  _num_0  \\\n",
       "399            bad    50         48    3.0   45.0        1452     808     644   \n",
       "487           best    49         47   45.0    2.0        1453     766     687   \n",
       "5098           too    42         35    5.0   30.0        1465     806     659   \n",
       "3228        moving    26         26   25.0    1.0        1474     786     688   \n",
       "225            and   923        739  444.0  295.0         761     367     394   \n",
       "1613  entertaining    23         23   22.0    1.0        1477     789     688   \n",
       "3143       minutes    23         22    2.0   20.0        1478     809     669   \n",
       "5036          this   206        201   80.0  121.0        1299     731     568   \n",
       "5577          with   198        183  126.0   57.0        1317     685     632   \n",
       "1458          dull    20         20    2.0   18.0        1480     809     671   \n",
       "5614         worst    17         16    1.0   15.0        1484     810     674   \n",
       "3425            or    65         59   17.0   42.0        1441     794     647   \n",
       "3322            no    47         44   11.0   33.0        1456     800     656   \n",
       "5540           why    15         15    1.0   14.0        1485     810     675   \n",
       "3579   performance    23         23   21.0    2.0        1477     790     687   \n",
       "3222         movie   223        220   92.0  128.0        1280     719     561   \n",
       "3672          plot    24         24    4.0   20.0        1476     807     669   \n",
       "2946          love    34         33   28.0    5.0        1467     783     684   \n",
       "3108          mess    14         14    1.0   13.0        1486     810     676   \n",
       "4567            so    77         73   24.0   49.0        1427     787     640   \n",
       "4309        script    26         25    5.0   20.0        1475     806     669   \n",
       "2086           get    19         19    3.0   16.0        1481     808     673   \n",
       "3580  performances    40         40   32.0    8.0        1460     779     681   \n",
       "5619         would    27         27    6.0   21.0        1473     805     668   \n",
       "1376   documentary    23         23   20.0    3.0        1477     791     686   \n",
       "259            any    42         42   12.0   30.0        1458     799     659   \n",
       "5508          well    49         45   35.0   10.0        1455     776     679   \n",
       "2650            it   364        320  147.0  173.0        1180     664     516   \n",
       "1804   fascinating    14         14   13.0    1.0        1486     798     688   \n",
       "3757   predictable    11         11    1.0   10.0        1489     810     679   \n",
       "2436            if    59         59   20.0   39.0        1441     791     650   \n",
       "1832         feels    17         17    3.0   14.0        1483     808     675   \n",
       "1887         first    28         27   22.0    5.0        1473     789     684   \n",
       "2924          long    19         19    4.0   15.0        1481     807     674   \n",
       "5513          were    20         19    4.0   15.0        1481     807     674   \n",
       "2386          hour    11         10    1.0    9.0        1490     810     680   \n",
       "2846          less    10         10    1.0    9.0        1490     810     680   \n",
       "5229          ugly    11         10    1.0    9.0        1490     810     680   \n",
       "5400         video    10         10    1.0    9.0        1490     810     680   \n",
       "3058           may    20         20   17.0    3.0        1480     794     686   \n",
       "3447           out    66         66   24.0   42.0        1434     787     647   \n",
       "2228          half    16         16    3.0   13.0        1484     808     676   \n",
       "2024           fun    23         23   19.0    4.0        1477     792     685   \n",
       "4171      romantic    16         16   14.0    2.0        1484     797     687   \n",
       "621      brilliant    12         12   11.0    1.0        1488     800     688   \n",
       "3066            me    18         18    4.0   14.0        1482     807     675   \n",
       "5082            to   529        435  211.0  224.0        1065     600     465   \n",
       "2171         great    23         22   18.0    4.0        1478     793     685   \n",
       "1776         fails     9          9    1.0    8.0        1491     810     681   \n",
       "2129          goes     9          9    1.0    8.0        1491     810     681   \n",
       "\n",
       "      information_gain  \n",
       "399           0.025357  \n",
       "487           0.020668  \n",
       "5098          0.011856  \n",
       "3228          0.011615  \n",
       "225           0.010230  \n",
       "1613          0.009924  \n",
       "3143          0.009830  \n",
       "5036          0.009135  \n",
       "5577          0.009075  \n",
       "1458          0.008500  \n",
       "5614          0.008294  \n",
       "3425          0.007706  \n",
       "3322          0.007619  \n",
       "5540          0.007599  \n",
       "3579          0.007478  \n",
       "3222          0.007472  \n",
       "3672          0.007036  \n",
       "2946          0.006939  \n",
       "3108          0.006910  \n",
       "4567          0.006720  \n",
       "4309          0.005986  \n",
       "2086          0.005845  \n",
       "3580          0.005804  \n",
       "5619          0.005604  \n",
       "1376          0.005583  \n",
       "259           0.005530  \n",
       "5508          0.005409  \n",
       "2650          0.005190  \n",
       "1804          0.005011  \n",
       "3757          0.004883  \n",
       "2436          0.004864  \n",
       "1832          0.004681  \n",
       "1887          0.004382  \n",
       "2924          0.004236  \n",
       "5513          0.004236  \n",
       "2386          0.004224  \n",
       "2846          0.004224  \n",
       "5229          0.004224  \n",
       "5400          0.004224  \n",
       "3058          0.004218  \n",
       "3447          0.004197  \n",
       "2228          0.004117  \n",
       "2024          0.004066  \n",
       "4171          0.004016  \n",
       "621           0.003970  \n",
       "3066          0.003714  \n",
       "5082          0.003661  \n",
       "2171          0.003656  \n",
       "1776          0.003577  \n",
       "2129          0.003577  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_voc_df.nlargest(50,'information_gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_voc_df.to_csv('store/vocabulary_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a neural network with the top 50 attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(neural_network)\n",
    "voca = new_voc_df.nlargest(50,'information_gain')['term']\n",
    "new_X_train = 1.*(d_t_ndarr[:,voca.index]>0)\n",
    "nn_structure = [50,50,2]\n",
    "W, b, avg_cost_func =neural_network.train_nn(nn_structure,new_X_train,new_y_train, 5000, alpha=0.55)\n",
    "# plot the avg_cost_func\n",
    "plt.plot(avg_cost_func)\n",
    "plt.ylabel('Average J')\n",
    "plt.xlabel('Iteration number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import importlib\n",
    "importlib.reload(neural_network)\n",
    "temp = vectorizer.transform(X_test)\n",
    "new_X_test = 1.*(temp[:,voca.index]>0).toarray()\n",
    "from sklearn.metrics import accuracy_score \n",
    "y_hat, y_pred = neural_network.predict_y(W, b, new_X_test, 3)\n",
    "print('Prediction accuracy is {}%'.format(accuracy_score(y_test, y_hat) * 100))\n",
    "print(confusion_matrix(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(neural_network)\n",
    "voca = new_voc_df.nlargest(50,'information_gain')['term']\n",
    "new_X_train = 1.*(d_t_ndarr[:,voca.index]>0)\n",
    "nn_structure = [50,50,2]\n",
    "W, b, avg_cost_func =neural_network.train_nn(nn_structure,new_X_train,new_y_train, 5000, alpha=0.6)\n",
    "# plot the avg_cost_func\n",
    "plt.plot(avg_cost_func)\n",
    "plt.ylabel('Average J')\n",
    "plt.xlabel('Iteration number')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import importlib\n",
    "importlib.reload(neural_network)\n",
    "temp = vectorizer.transform(X_test)\n",
    "new_X_test = 1.*(temp[:,voca.index]>0).toarray()\n",
    "from sklearn.metrics import accuracy_score \n",
    "y_hat, y_pred = neural_network.predict_y(W, b, new_X_test, 3)\n",
    "print('Prediction accuracy is {}%'.format(accuracy_score(y_test, y_hat) * 100))\n",
    "print(confusion_matrix(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covert y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neural_network \n",
    "import importlib\n",
    "importlib.reload(neural_network)\n",
    "\n",
    "new_y_train=neural_network.convert_y_to_vect(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cureent candidate(0/48): 50\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 68.8%\n",
      "[[115 112]\n",
      " [ 44 229]]\n",
      "Cureent candidate(1/48): 70\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 70.8%\n",
      "[[127 100]\n",
      " [ 46 227]]\n",
      "Cureent candidate(2/48): 90\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 71.2%\n",
      "[[131  96]\n",
      " [ 48 225]]\n",
      "Cureent candidate(3/48): 110\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 72.0%\n",
      "[[134  93]\n",
      " [ 47 226]]\n",
      "Cureent candidate(4/48): 130\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 72.6%\n",
      "[[140  87]\n",
      " [ 50 223]]\n",
      "Cureent candidate(5/48): 150\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 73.0%\n",
      "[[139  88]\n",
      " [ 47 226]]\n",
      "Cureent candidate(6/48): 170\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 71.8%\n",
      "[[136  91]\n",
      " [ 50 223]]\n",
      "Cureent candidate(7/48): 190\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 72.6%\n",
      "[[141  86]\n",
      " [ 51 222]]\n",
      "Cureent candidate(8/48): 210\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 72.0%\n",
      "[[141  86]\n",
      " [ 54 219]]\n",
      "Cureent candidate(9/48): 230\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 72.6%\n",
      "[[142  85]\n",
      " [ 52 221]]\n",
      "Cureent candidate(10/48): 250\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 71.8%\n",
      "[[145  82]\n",
      " [ 59 214]]\n",
      "Cureent candidate(11/48): 270\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 70.8%\n",
      "[[145  82]\n",
      " [ 64 209]]\n",
      "Cureent candidate(12/48): 290\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 70.8%\n",
      "[[145  82]\n",
      " [ 64 209]]\n",
      "Cureent candidate(13/48): 310\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 71.6%\n",
      "[[146  81]\n",
      " [ 61 212]]\n",
      "Cureent candidate(14/48): 330\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 71.2%\n",
      "[[146  81]\n",
      " [ 63 210]]\n",
      "Cureent candidate(15/48): 350\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 70.6%\n",
      "[[144  83]\n",
      " [ 64 209]]\n",
      "Cureent candidate(16/48): 370\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 70.6%\n",
      "[[146  81]\n",
      " [ 66 207]]\n",
      "Cureent candidate(17/48): 390\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 71.6%\n",
      "[[147  80]\n",
      " [ 62 211]]\n",
      "Cureent candidate(18/48): 410\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 71.2%\n",
      "[[148  79]\n",
      " [ 65 208]]\n",
      "Cureent candidate(19/48): 430\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 70.6%\n",
      "[[146  81]\n",
      " [ 66 207]]\n",
      "Cureent candidate(20/48): 450\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 71.2%\n",
      "[[148  79]\n",
      " [ 65 208]]\n",
      "Cureent candidate(21/48): 470\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n",
      "Prediction accuracy is 71.8%\n",
      "[[149  78]\n",
      " [ 63 210]]\n",
      "Cureent candidate(22/48): 490\n",
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n"
     ]
    }
   ],
   "source": [
    "n_candidates= np.arange(50,1000,20)\n",
    "W_m = []\n",
    "avg_cost_func_m = []\n",
    "b_m = []\n",
    "y_pred_m = []\n",
    "temp = vectorizer.transform(X_test)\n",
    "for i,c in enumerate(n_candidates): \n",
    "    print(f'Cureent candidate({i}/{len(n_candidates)}): {c}')\n",
    "    voca = new_voc_df.nlargest(c,'information_gain')['term']\n",
    "    new_X_train = 1.*(d_t_ndarr[:,voca.index]>0)\n",
    "    new_X_test = 1.*(temp[:,voca.index]>0).toarray()\n",
    "    nn_structure = [c,50,2]\n",
    "    W, b, avg_cost_func =neural_network.train_nn(nn_structure, new_X_train, new_y_train, 5000, alpha=0.55)\n",
    "    y_hat, y_pred = neural_network.predict_y(W, b, new_X_test, 3)\n",
    "    print('Prediction accuracy is {}%'.format(accuracy_score(y_test, y_hat) * 100))\n",
    "    print(confusion_matrix(y_test,y_hat))\n",
    "    plt.figure()\n",
    "    plt.plot(avg_cost_func)\n",
    "    plt.ylabel('Average J')\n",
    "    plt.xlabel('Iteration number')\n",
    "    plt.show()\n",
    "\n",
    "    avg_cost_func_m.append(avg_cost_func)\n",
    "    W_m.append(W)\n",
    "    b_m.append(b)\n",
    "    y_pred_m.append(y_pred)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('weights_matrix', W_m)\n",
    "np.save('bias_matrix', b_m)\n",
    "np.save('predictions_matrix', y_pred_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Zero-R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5406666666666666"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum()/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy is 54.6%\n"
     ]
    }
   ],
   "source": [
    "print('Prediction accuracy is {}%'.format(accuracy_score(y_test,[1]*len(y_test)) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
